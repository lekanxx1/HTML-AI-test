<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Read Aloud with Speech Recognition</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }
        #book-content { max-width: 800px; margin: 0 auto; }
        #feedback { margin-top: 20px; color: red; }
        #transcription { margin-top: 20px; color: green; }
        button { padding: 10px 20px; font-size: 16px; }
    </style>
</head>
<body>
    <div id="book-content">
        <h1>Read Aloud with Speech Recognition</h1>
        <p id="current-paragraph">
            These two very old people are the father and mother of Mr. Bucket. Their names are Grandpa Joe and Grandma Josephine.
        </p>
        <button id="start-recording">Start Recording</button>
        <button id="stop-recording" disabled>Stop Recording</button>
        <div id="feedback"></div>
        <div id="transcription"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];

        const startButton = document.getElementById('start-recording');
        const stopButton = document.getElementById('stop-recording');
        const feedback = document.getElementById('feedback');
        const transcriptionDisplay = document.getElementById('transcription');

        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();

                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = sendAudioForTranscription;

                    startButton.disabled = true;
                    stopButton.disabled = false;
                    feedback.textContent = 'Recording...';
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                    feedback.textContent = 'Error accessing microphone';
                });
        }

        function stopRecording() {
            mediaRecorder.stop();
            startButton.disabled = false;
            stopButton.disabled = true;
            feedback.textContent = 'Processing...';
        }

        function sendAudioForTranscription() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const reader = new FileReader();

            reader.onloadend = () => {
                const audioBase64 = reader.result.split(',')[1];

                fetch('/transcribe', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ audioData: audioBase64 })
                })
                .then(response => response.json())
                .then(data => {
                    feedback.textContent = '';
                    transcriptionDisplay.textContent = `Transcription: ${data.transcription}`;
                    audioChunks = [];
                })
                .catch(error => {
                    console.error('Error during transcription:', error);
                    feedback.textContent = 'Error during transcription';
                    audioChunks = [];
                });
            };

            reader.readAsDataURL(audioBlob);
        }
    </script>
</body>
</html>
